{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Review Classification\n",
    "\n",
    "Note: this task is completed via Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpRkNE9S1W5L"
   },
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "import nltk\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMf9SlU71W5T"
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "manual_seed = 123\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "6x_Nrz8iYJlu",
    "outputId": "a8d3a23b-7644-4479-85da-0ff600bc5102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tetguW9zIeRb"
   },
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "\n",
    "# option 1: spacy\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "#option 2: nltk\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxQIpvgN_EM5"
   },
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "\n",
    "from torchtext.vocab import Vectors\n",
    "vectors = Vectors(name = 'glove.840B.300d.txt', cache = \"./drive/My Drive/yelp_review/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpCvjKdf1W5c"
   },
   "outputs": [],
   "source": [
    "# remove stopwords if needed\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# define batch size\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# define field\n",
    "TEXT = Field(sequential=True, tokenize=word_tokenize, lower=True)\n",
    "LABEL = Field(sequential=False, unk_token = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vL2JDMuEKuMG"
   },
   "outputs": [],
   "source": [
    "# Load train and validation set\n",
    "train, val= TabularDataset.splits(\n",
    "               path=\"./drive/My Drive/yelp_review/\", # the root directory where the data lies\n",
    "               train='train.tsv', validation=\"val.tsv\",  # file names\n",
    "               format='tsv',\n",
    "               skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "               fields=[('tweet', TEXT), ('label', LABEL)])\n",
    "\n",
    "# Build vocabulary\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 3)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "# split train and val\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (train, val), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_sizes=(BATCH_SIZE,BATCH_SIZE),\n",
    " sort_key=lambda x: len(x.tweet), \n",
    "#  device = device, \n",
    " sort=True,\n",
    "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
    " sort_within_batch=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srT9LinN1W5f"
   },
   "outputs": [],
   "source": [
    "# prepare test set\n",
    "\n",
    "test = TabularDataset(\n",
    "    path = \"./drive/My Drive/yelp_review/test.tsv\",\n",
    "    format = 'tsv',\n",
    "    skip_header = True,\n",
    "    fields = [('tweet', TEXT)]\n",
    ")\n",
    "\n",
    "test_iter = Iterator(\n",
    "    dataset = test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = None,\n",
    "    sort = False,\n",
    "    shuffle = False,\n",
    "    sort_within_batch = False,\n",
    "    device = device,\n",
    "    train = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4bVSvKT1W5k"
   },
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "  \n",
    "  def __init__(self, embedding_size, vocab_size, output_size, hidden_size, num_layers):\n",
    "    # In the constructor we define the layers for our model (same as our previous RNN)\n",
    "    super(LSTMmodel, self).__init__()\n",
    "    # word embedding lookup table\n",
    "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size).from_pretrained(TEXT.vocab.vectors, freeze = False)\n",
    "    #self.embedding.weight.data.normal_(0.0,0.05) # mean=0.0, mu=0.05\n",
    "    #self.embedding.weight.copy_(torch.from_numpy(pretrained_weight)) #if have pre-trained weights\n",
    "    \n",
    "    # core LSTM module\n",
    "    DROPOUT_RATE = 0.2\n",
    "    #baseline:\n",
    "    #self.lstm_rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) # input_size, hidden_size, num_layers\n",
    "\n",
    "    #with droptout:\n",
    "    self.lstm_rnn = nn.LSTM(input_size=embedding_size, dropout=DROPOUT_RATE, hidden_size=hidden_size, num_layers=num_layers) # input_size, hidden_size, num_layers\n",
    "\n",
    "    # to get bi-direction:\n",
    "    #self.lstm_rnn = nn.LSTM(input_size=embedding_size, bidirectional=True, dropout=DROPOUT_RATE, hidden_size=hidden_size, num_layers=num_layers) # input_size, hidden_size, num_layers\n",
    "    \n",
    "    self.activation_fn = nn.Sigmoid()\n",
    "    self.linear_layer = nn.Linear(hidden_size, output_size) \n",
    "\n",
    "    self.softmax_layer = nn.LogSoftmax(dim=0)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # In the forward function we define the forward propagation logic\n",
    "    out = self.embedding(x)\n",
    "    #out, (h_state, c_state) = self.lstm_rnn(out) # h_0 initialized to zeros by default\n",
    "    out, _ = self.lstm_rnn(out, None) # h_0 initialized to zeros by default\n",
    "    # classify based on the hidden representation at the last token\n",
    "    out = out[-1] # unsqueeze converts 1D input (D dimension) into 2D input (1xD) \n",
    "    #out = self.activation_fn(out)\n",
    "    out = self.linear_layer(out)\n",
    "    out = self.softmax_layer(out) # accepts 2D or more dimensional inputs\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Ng_VoNS5_tph",
    "outputId": "d2cb5a1b-8d03-4228-8f16-e7cd0c573732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMmodel(\n",
      "  (embedding): Embedding(18608, 300)\n",
      "  (lstm_rnn): LSTM(300, 512, num_layers=4, dropout=0.2)\n",
      "  (activation_fn): Sigmoid()\n",
      "  (linear_layer): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (softmax_layer): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define hyper-parameters\n",
    "EMBEDDING_SIZE = 300 \n",
    "VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
    "NUM_CLASSES = 5\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 4\n",
    "model = LSTMmodel(EMBEDDING_SIZE, VOCAB_SIZE, NUM_CLASSES, HIDDEN_SIZE, NUM_LAYERS)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "LEARNING_RATE = 0.2\n",
    "criterion = nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbtpGCa7_wdk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(loader):\n",
    "    total_loss = 0.0\n",
    "    # iterate throught the data loader\n",
    "    num_sample = 0\n",
    "    for batch in loader:\n",
    "        # load the current batch\n",
    "        batch_input = batch.tweet\n",
    "        batch_output = batch.label\n",
    "        \n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_output = batch_output.to(device)\n",
    "        # forward propagation\n",
    "        # pass the data through the model\n",
    "        model_outputs = model(batch_input)\n",
    "        # compute the loss\n",
    "        \n",
    "        cur_loss = criterion(model_outputs, batch_output)\n",
    "        \n",
    "        \n",
    "        total_loss += cur_loss.item() #+ len(batch)*lambda_1*l1_pen\n",
    "\n",
    "        # backward propagation (compute the gradients and update the model)\n",
    "        # clear the buffer\n",
    "        optimizer.zero_grad()\n",
    "        # compute the gradients\n",
    "        cur_loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        num_sample += batch_output.shape[0]\n",
    "    return total_loss/num_sample\n",
    "\n",
    "# evaluation logic based on classification accuracy\n",
    "def evaluate(loader):\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
    "        for batch in loader:\n",
    "             # load the current batch\n",
    "            batch_input = batch.tweet\n",
    "            batch_output = batch.label\n",
    "\n",
    "            batch_input = batch_input.to(device)\n",
    "            # forward propagation\n",
    "            # pass the data through the model\n",
    "            model_outputs = model(batch_input)\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(batch_output)\n",
    "\n",
    "            \n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return accuracy,f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "8lEAlJgn_0QB",
    "outputId": "1b2ba6f5-42e6-4c04-9395-1d00bd3faeef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1065, Training Accuracy: 0.2040, Validation Accuracy: 0.2066, F1 score :0.2000\n",
      "Epoch [2/20], Loss: 0.1076, Training Accuracy: 0.2615, Validation Accuracy: 0.2743, F1 score :0.2573\n",
      "Epoch [3/20], Loss: 0.1042, Training Accuracy: 0.2579, Validation Accuracy: 0.2434, F1 score :0.2193\n",
      "Epoch [4/20], Loss: 0.0968, Training Accuracy: 0.4396, Validation Accuracy: 0.4260, F1 score :0.4041\n",
      "Epoch [5/20], Loss: 0.0909, Training Accuracy: 0.5383, Validation Accuracy: 0.5274, F1 score :0.5170\n",
      "Epoch [6/20], Loss: 0.0883, Training Accuracy: 0.5641, Validation Accuracy: 0.5297, F1 score :0.5128\n",
      "Epoch [7/20], Loss: 0.0866, Training Accuracy: 0.5857, Validation Accuracy: 0.5574, F1 score :0.5471\n",
      "Epoch [8/20], Loss: 0.0851, Training Accuracy: 0.6371, Validation Accuracy: 0.5829, F1 score :0.5794\n",
      "Epoch [9/20], Loss: 0.0836, Training Accuracy: 0.6528, Validation Accuracy: 0.5766, F1 score :0.5756\n",
      "Epoch [10/20], Loss: 0.0825, Training Accuracy: 0.6803, Validation Accuracy: 0.6046, F1 score :0.6006\n",
      "Epoch [11/20], Loss: 0.0811, Training Accuracy: 0.6950, Validation Accuracy: 0.5877, F1 score :0.5882\n",
      "Epoch [12/20], Loss: 0.0797, Training Accuracy: 0.7164, Validation Accuracy: 0.5891, F1 score :0.5884\n",
      "Epoch [13/20], Loss: 0.0789, Training Accuracy: 0.7343, Validation Accuracy: 0.5886, F1 score :0.5876\n",
      "Epoch [14/20], Loss: 0.0777, Training Accuracy: 0.7394, Validation Accuracy: 0.5806, F1 score :0.5771\n",
      "Epoch [15/20], Loss: 0.0767, Training Accuracy: 0.7550, Validation Accuracy: 0.5894, F1 score :0.5894\n",
      "Epoch [16/20], Loss: 0.0759, Training Accuracy: 0.7708, Validation Accuracy: 0.5777, F1 score :0.5741\n",
      "Epoch [17/20], Loss: 0.0751, Training Accuracy: 0.7945, Validation Accuracy: 0.5751, F1 score :0.5724\n",
      "Epoch [18/20], Loss: 0.0740, Training Accuracy: 0.7999, Validation Accuracy: 0.5746, F1 score :0.5741\n",
      "Epoch [19/20], Loss: 0.0732, Training Accuracy: 0.7886, Validation Accuracy: 0.5700, F1 score :0.5605\n",
      "Epoch [20/20], Loss: 0.0725, Training Accuracy: 0.8102, Validation Accuracy: 0.5754, F1 score :0.5691\n"
     ]
    }
   ],
   "source": [
    "manual_seed = 123\n",
    "torch.manual_seed(manual_seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "max_epoch = 20\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=.9, weight_decay=.00001)\n",
    "\n",
    "# start the training\n",
    "for epoch in range(max_epoch):\n",
    "    # train the model for one pass over the data\n",
    "    train_loss = train(train_iter)  \n",
    "    # compute the training accuracy\n",
    "    train_acc,f1t = evaluate(train_iter)\n",
    "    # compute the validation accuracy\n",
    "    val_acc,f1v = evaluate(val_iter)\n",
    "    \n",
    "    # print the loss for every epoch\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Training Accuracy: {:.4f}, Validation Accuracy: {:.4f}, F1 score :{:.4f}'.format(epoch+1, max_epoch, train_loss, train_acc, val_acc, f1v))\n",
    "\n",
    "    model_save = {\n",
    "            'epoch': epoch,  # number of epoch\n",
    "            'model_state_dict': model.state_dict(), # model parameters \n",
    "            'optimizer_state_dict': optimizer.state_dict(), # save optimizer \n",
    "            'loss': train_loss # training loss\n",
    "            }\n",
    "    \n",
    "    # use torch.save to store \n",
    "    torch.save(model_save, \"./ckpt/model_{}.pt\".format(epoch+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CdH8WWClbTt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab4_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
